import warnings
import numpy as np
import cv2
import os
import scipy.io
from skimage.feature import hog
from sklearn.svm import LinearSVC
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.cluster import DBSCAN
from collections import defaultdict
import time

# -----------------------------------
# Thông số HOG & Sliding Window
# -----------------------------------
HOG_PARAMS = {
    'orientations': 9,
    'pixels_per_cell': (8, 8),
    'cells_per_block': (2, 2),
    'block_norm': 'L2-Hys',
    'transform_sqrt': True,
    'feature_vector': True,
}

# Cấu hình tối ưu cho sliding window
WINDOW_STEP = 8
SCALES     = [0.3, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6]
CONF_THRESH = 0.4
NMS_THRESH  = 0.4
MIN_FACE_SIZE = 15
MAX_FACE_SIZE = 300

# -----------------------------------
# 1. Load .mat & trích xuất HOG features
# -----------------------------------
def load_hog_dataset(pos_path, neg_path):
    mat_pos = scipy.io.loadmat(pos_path)['possamples']
    mat_neg = scipy.io.loadmat(neg_path)['negsamples']
    
    def to_images(mat):
        if mat.ndim == 3:
            h, w, n = mat.shape
            imgs = np.transpose(mat, (2, 0, 1)).astype('float32')
            return imgs, (h, w)
        elif mat.ndim == 2:
            n, feats = mat.shape
            side = int(np.sqrt(feats))
            imgs = mat.reshape(n, side, side).astype('float32')
            return imgs, (side, side)
        else:
            raise ValueError("Unsupported .mat array shape")
    
    pos_imgs, (h_pos, w_pos) = to_images(mat_pos)
    neg_imgs, (h_neg, w_neg) = to_images(mat_neg)
    
    assert (h_pos, w_pos) == (h_neg, w_neg), "Positive/negative sizes differ!"
    H, W = h_pos, w_pos

    def compute_hog(imgs):
        feats = []
        for im in imgs:
            im_norm = cv2.normalize(im, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')
            fd = hog(im_norm, **HOG_PARAMS)
            feats.append(fd)
        return np.array(feats)
    
    X_pos = compute_hog(pos_imgs)
    X_neg = compute_hog(neg_imgs)
    
    X = np.vstack((X_pos, X_neg))
    y = np.hstack((np.ones(len(X_pos)), np.zeros(len(X_neg))))
    return X, y, (H, W)

# -----------------------------------
# 2. Soft-Non Maximum Suppression
# -----------------------------------
def soft_nms(boxes, scores, iou_thr=0.2, sigma=0.6, thresh=0.001):
    """
    Soft-NMS cải tiến: giảm trọng số confidence thay vì loại bỏ hoàn toàn
    """
    if len(boxes) == 0:
        return [], []
    
    boxes = np.array(boxes)
    scores = np.array(scores)
    
    x1 = boxes[:, 0]
    y1 = boxes[:, 1]
    x2 = boxes[:, 0] + boxes[:, 2]
    y2 = boxes[:, 1] + boxes[:, 3]
    areas = (x2 - x1) * (y2 - y1)
    
    # Khởi tạo chỉ số
    indices = np.arange(len(boxes))
    for i in range(len(boxes)):
        # Tìm box có điểm cao nhất
        max_idx = i
        for j in range(i + 1, len(boxes)):
            if scores[indices[j]] > scores[indices[max_idx]]:
                max_idx = j
        
        # Hoán đổi chỉ số
        indices[i], indices[max_idx] = indices[max_idx], indices[i]
        
        # Tính IoU với các box còn lại
        xx1 = np.maximum(x1[indices[i]], x1[indices[i+1:]])
        yy1 = np.maximum(y1[indices[i]], y1[indices[i+1:]])
        xx2 = np.minimum(x2[indices[i]], x2[indices[i+1:]])
        yy2 = np.minimum(y2[indices[i]], y2[indices[i+1:]])
        
        w = np.maximum(0.0, xx2 - xx1)
        h = np.maximum(0.0, yy2 - yy1)
        intersection = w * h
        iou = intersection / (areas[indices[i]] + areas[indices[i+1:]] - intersection + 1e-10)
        
        # Giảm trọng số các box chồng chéo
        weights = np.exp(-(iou * iou) / sigma)
        scores[indices[i+1:]] *= weights
    
    # Lọc các box có điểm số trên ngưỡng
    keep = indices[scores[indices] > thresh]
    return boxes[keep], scores[keep]

# -----------------------------------
# 3. Phát hiện khuôn mặt
# -----------------------------------
def detect_faces(img, model, scaler, 
                 window_size,     # from load_hog_dataset
                 step=WINDOW_STEP, scales=SCALES,
                 conf_thr=CONF_THRESH, nms_thr=NMS_THRESH):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    gray = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8,8)).apply(gray)

    ih, iw = gray.shape
    wh, ww = window_size
    all_boxes, all_scores = [], []

    for scale in scales:
        sw, sh = int(iw*scale), int(ih*scale)
        resized = cv2.resize(gray, (sw, sh))
        # điều chỉnh bước quét theo scale
        adaptive_step = max(4, int(step * scale))

        for y in range(0, sh - int(wh*scale) + 1, adaptive_step):
            for x in range(0, sw - int(ww*scale) + 1, adaptive_step):
                patch = resized[y:y+int(wh*scale), x:x+int(ww*scale)]
                # đảm bảo patch về đúng window_size
                patch = cv2.resize(patch, window_size)

                fd = hog(patch, **HOG_PARAMS).reshape(1, -1)
                fd = scaler.transform(fd)
                score = model.decision_function(fd)[0]

                if score > conf_thr:
                    # back to original coords
                    ox = int(x/scale)
                    oy = int(y/scale)
                    ow = int(ww/scale)
                    oh = int(wh/scale)
                    # lọc kích thước hợp lý
                    if MIN_FACE_SIZE <= ow <= MAX_FACE_SIZE \
                       and MIN_FACE_SIZE <= oh <= MAX_FACE_SIZE \
                       and 0.7 <= ow/oh <= 1.4:
                        all_boxes.append([ox, oy, ow, oh])
                        all_scores.append(score)

    if not all_boxes:
        return np.empty((0,4)), np.array([])

    # Soft-NMS + clustering giữ nguyên
    boxes, scores = soft_nms(all_boxes, all_scores, iou_thr=nms_thr)
    boxes, scores = cluster_detections(boxes, scores, img.shape)

    return boxes, scores

def cluster_detections(boxes, scores, img_shape):
    """
    Phân cụm các detection gần nhau và tính điểm trung bình
    """
    # Tính tọa độ trung tâm
    centers = np.array([[x + w/2, y + h/2] for x, y, w, h in boxes])
    
    # Phân cụm DBSCAN
    db = DBSCAN(eps=min(img_shape[:2])/10, min_samples=1).fit(centers)
    labels = db.labels_
    
    # Nhóm các detection theo cụm
    clusters = defaultdict(list)
    for i, label in enumerate(labels):
        clusters[label].append((boxes[i], scores[i]))
    
    # Tính kết quả trung bình cho mỗi cụm
    final_boxes = []
    final_scores = []
    
    for label, detections in clusters.items():
        if len(detections) == 0:
            continue
            
        # Tính box trung bình
        avg_box = np.mean([box for box, _ in detections], axis=0)
        avg_score = np.mean([score for _, score in detections])
        
        # Chỉ giữ lại cụm có điểm trung bình cao
        if avg_score > CONF_THRESH * 0.8:
            final_boxes.append(avg_box)
            final_scores.append(avg_score)
    
    return np.array(final_boxes), np.array(final_scores)

# -----------------------------------
# 4. Kiểm tra đặc điểm khuôn mặt
# -----------------------------------
def validate_face(img, box, min_valid_eyes=1):
    x, y, w, h = map(int, box)
    face_roi = img[y:y+h, x:x+w]

    if face_roi.size == 0:
        return False

    gray_face = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)

    # Nếu khuôn mặt quá nhỏ, dùng độ tương phản + hình dạng
    if w < 40 or h < 40:
        contrast = np.std(gray_face)
        aspect_ratio = w / h
        if contrast < 15 or aspect_ratio < 0.5 or aspect_ratio > 1.5:
            return False
        return True

    # Dùng cascade mắt nếu khuôn mặt đủ lớn
    eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')
    if eye_cascade.empty():
        return True

    eyes = eye_cascade.detectMultiScale(
        gray_face,
        scaleFactor=1.1,
        minNeighbors=3,
        minSize=(int(w * 0.08), int(h * 0.08)),
        flags=cv2.CASCADE_SCALE_IMAGE
    )

    # Chấp nhận nếu có ít nhất 1 mắt nằm trong nửa trên
    for (ex, ey, ew, eh) in eyes:
        if ey + eh/2 < h * 0.7:
            return True

    return False

# -----------------------------------
# 5. Hiển thị kết quả
# -----------------------------------
def visualize_results(img, boxes, scores, title="Kết quả nhận diện"):
    img_display = img.copy()
    if len(img_display.shape) == 2:
        img_display = cv2.cvtColor(img_display, cv2.COLOR_GRAY2BGR)
    
    # Sắp xếp theo confidence để vẽ box tốt nhất cuối cùng
    sorted_indices = np.argsort(scores)
    
    for i in sorted_indices:
        x, y, w, h = map(int, boxes[i])
        score = scores[i]
        
        # Màu sắc dựa trên confidence
        color_intensity = min(255, int(255 * score / max(1, np.max(scores) * 1.5)))
        color = (0, color_intensity, 255 - color_intensity)
        
        cv2.rectangle(img_display, (x, y), (x+w, y+h), color, 2)
        cv2.putText(img_display, f"{score:.2f}", (x, y-5),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
    
    # Chuyển sang RGB để hiển thị
    img_rgb = cv2.cvtColor(img_display, cv2.COLOR_BGR2RGB)
    
    plt.figure(figsize=(10, 8))
    plt.imshow(img_rgb)
    plt.title(f"{title} - {len(boxes)} khuôn mặt")
    plt.axis('off')
    plt.show()
    
    return img_display

# -----------------------------------
# 6. Main: Load → Train → Test
# -----------------------------------
if __name__ == "__main__":
    base_dir = r"D:\HTTT\AI\face_recognition"
    pos_mat = os.path.join(base_dir, "possamples.mat")
    neg_mat = os.path.join(base_dir, "negsamples.mat")
    
    print("1) Load dataset & extract HOG …")
    X, y, window = load_hog_dataset(pos_mat, neg_mat)
    print(f"   Dataset size: {X.shape}, window: {window}")
    
    print("2) Scale features & split …")
    scaler = StandardScaler().fit(X)
    Xs = scaler.transform(X)
    Xtr, Xva, ytr, yva = train_test_split(Xs, y, test_size=0.2, random_state=42)
    
    print("3) Train SVM with optimized parameters …")
    clf = LinearSVC(C=0.5, max_iter=10000, random_state=42, class_weight='balanced')
    clf.fit(Xtr, ytr)
    
    train_acc = clf.score(Xtr, ytr)
    val_acc = clf.score(Xva, yva)
    print(f"   Train accuracy: {train_acc:.4f}, Validation accuracy: {val_acc:.4f}")
    
    print("4) Recognize faces on test images …")
    test_images = []
    for i in range(5, 6):
        path = os.path.join(base_dir, f"img{i}.jpg")
        if os.path.exists(path):
            test_images.append(path)
    
    for img_path in test_images:
        img = cv2.imread(img_path)
        if img is None:
            print(f"   Không đọc được {img_path}")
            continue
        
        print(f"\nProcessing: {os.path.basename(img_path)}")
        start_time = time.time()

        # Phát hiện khuôn mặt
        boxes, scores = detect_faces(img, clf, scaler, window_size=window)
        
        # Lọc kết quả bằng đặc điểm khuôn mặt
        valid_boxes = []
        valid_scores = []
        MIN_SCORE = 0.6
        for box, score in zip(boxes, scores):
            if score < MIN_SCORE:
                continue
            if validate_face(img, box):
                valid_boxes.append(box)
                valid_scores.append(score)
        
        # Chuyển đổi sang mảng numpy
        valid_boxes = np.array(valid_boxes)
        valid_scores = np.array(valid_scores)
        
        process_time = time.time() - start_time
        print(f"   Thời gian xử lý: {process_time:.2f}s")
        print(f"   Số khuôn mặt phát hiện: {len(valid_boxes)}")
        
        # Hiển thị kết quả
        filename = os.path.basename(img_path)
        title = f"{filename} - {len(valid_boxes)} faces"
        visualize_results(img, valid_boxes, valid_scores, title)